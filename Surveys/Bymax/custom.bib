@book{ abelson-et-al:scheme,
  author = "Harold Abelson and Gerald~Jay Sussman and Julie Sussman",
  title = "Structure and Interpretation of Computer Programs",
  publisher = "MIT Press",
  address = "Cambridge, Massachusetts",
  year = "1985"
}

@inproceedings{ bgf:Lixto,
  author = "Robert Baumgartner and Georg Gottlob and Sergio Flesca",
  title = "Visual Information Extraction with {Lixto}",
  booktitle = "Proceedings of the 27th International Conference on Very Large Databases",
  pages = "119--128",
  publisher = "Morgan Kaufmann",
  address = "Rome, Italy",
  month = "September",
  year = "2001"
}

@ARTICLE{10.3389/frai.2022.879603,
AUTHOR={Kiseleva, Anastasiya  and Kotzinos, Dimitris  and De Hert, Paul },
TITLE={Transparency of AI in Healthcare as a Multilayered System of Accountabilities: Between Legal Requirements and Technical Limitations},
JOURNAL={Frontiers in Artificial Intelligence},
VOLUME={5},
YEAR={2022},
URL={https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2022.879603},
DOI={10.3389/frai.2022.879603},
ISSN={2624-8212},
ABSTRACT={<p>The lack of transparency is one of the artificial intelligence (AI)'s fundamental challenges, but the concept of transparency might be even more opaque than AI itself. Researchers in different fields who attempt to provide the solutions to improve AI's transparency articulate different but neighboring concepts that include, besides transparency, explainability and interpretability. Yet, there is no common taxonomy neither within one field (such as data science) nor between different fields (law and data science). In certain areas like healthcare, the requirements of transparency are crucial since the decisions directly affect people's lives. In this paper, we suggest an interdisciplinary vision on how to tackle the issue of AI's transparency in healthcare, and we propose a single point of reference for both legal scholars and data scientists on transparency and related concepts. Based on the analysis of the European Union (EU) legislation and literature in computer science, we submit that transparency shall be considered the “way of thinking” and umbrella concept characterizing the process of AI's development and use. Transparency shall be achieved through a set of measures such as interpretability and explainability, communication, auditability, traceability, information provision, record-keeping, data governance and management, and documentation. This approach to deal with transparency is of general nature, but transparency measures shall be always contextualized. By analyzing transparency in the healthcare context, we submit that it shall be viewed as a system of accountabilities of involved subjects (AI developers, healthcare professionals, and patients) distributed at different layers (insider, internal, and external layers, respectively). The transparency-related accountabilities shall be built-in into the existing accountability picture which justifies the need to investigate the relevant legal frameworks. These frameworks correspond to different layers of the transparency system. The requirement of informed medical consent correlates to the external layer of transparency and the Medical Devices Framework is relevant to the insider and internal layers. We investigate the said frameworks to inform AI developers on what is already expected from them with regards to transparency. We also discover the gaps in the existing legislative frameworks concerning AI's transparency in healthcare and suggest the solutions to fill them in.</p>}
}

@Article{electronics13112002,
AUTHOR = {Zhang, Luyao and Shu, Jianhua and Hu, Jili and Li, Fangfang and He, Junjun and Wang, Peng and Shen, Yiqing},
TITLE = {Exploring the Potential of Large Language Models in Radiological Imaging Systems: Improving User Interface Design and Functional Capabilities},
JOURNAL = {Electronics},
VOLUME = {13},
YEAR = {2024},
NUMBER = {11},
ARTICLE-NUMBER = {2002},
URL = {https://www.mdpi.com/2079-9292/13/11/2002},
ISSN = {2079-9292},
ABSTRACT = {Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks, including conversation, in-context learning, reasoning, and code generation. This paper explores the potential application of LLMs in radiological information systems (RIS) and assesses the impact of integrating LLMs on RIS development and human–computer interaction. We present ChatUI-RIS, a prototype chat-based user interface that leverages LLM capabilities to enhance RIS functionality and user experience. Through an exploratory study involving 26 medical students, we investigate the efficacy of natural language dialogue for learning and operating RIS. Our findings suggest that LLM integration via a chat interface can significantly improve operational efficiency, reduce learning time, and facilitate rapid expansion of RIS capabilities. By interacting with ChatUI-RIS using natural language instructions, medical students can access and retrieve radiology information in a conversational manner. The LLM-powered chat interface not only streamlines user interactions, but also enables more intuitive and efficient navigation of complex RIS functionalities. Furthermore, the natural language processing capabilities of LLMs can be harnessed to automatically generate code snippets and database queries, accelerating RIS development and customization. Preliminary observations indicate that integrating LLMs in RIS has the potential to revolutionize user interface design, enhance system capabilities, and ultimately improve the overall user experience for radiologists and medical professionals.},
DOI = {10.3390/electronics13112002}
}

@article{reddy2024generative,
  title={Generative AI in healthcare: an implementation science informed translational path on application, integration and governance},
  author={Reddy, Sandeep},
  journal={Implementation Science},
  volume={19},
  number={1},
  pages={27},
  year={2024},
  publisher={Springer}
}

@misc{strong2024humanaicollaborationhealthcareguided,
      title={Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems with Large Language Models}, 
      author={Joshua Strong and Qianhui Men and Alison Noble},
      year={2024},
      eprint={2406.07212},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.07212}, 
}

@misc{chu2024professionalagentsevolving,
      title={Professional Agents -- Evolving Large Language Models into Autonomous Experts with Human-Level Competencies}, 
      author={Zhixuan Chu and Yan Wang and Feng Zhu and Lu Yu and Longfei Li and Jinjie Gu},
      year={2024},
      eprint={2402.03628},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.03628}, 
}

@misc{ling2024domainspecializationkeymake,
      title={Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey}, 
      author={Chen Ling and Xujiang Zhao and Jiaying Lu and Chengyuan Deng and Can Zheng and Junxiang Wang and Tanmoy Chowdhury and Yun Li and Hejie Cui and Xuchao Zhang and Tianjiao Zhao and Amit Panalkar and Dhagash Mehta and Stefano Pasquali and Wei Cheng and Haoyu Wang and Yanchi Liu and Zhengzhang Chen and Haifeng Chen and Chris White and Quanquan Gu and Jian Pei and Carl Yang and Liang Zhao},
      year={2024},
      eprint={2305.18703},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.18703}, 
}

@misc{hong2024metagptmetaprogrammingmultiagent,
      title={MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework}, 
      author={Sirui Hong and Mingchen Zhuge and Jiaqi Chen and Xiawu Zheng and Yuheng Cheng and Ceyao Zhang and Jinlin Wang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and Jürgen Schmidhuber},
      year={2024},
      eprint={2308.00352},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2308.00352}, 
}

@article{ brachman-schmolze:kl-one,
  author = "Ronald~J. Brachman and James~G. Schmolze",
  title = "An overview of the {KL-ONE} knowledge representation system",
  journal = "Cognitive Science",
  volume = "9",
  number = "2",
  pages = "171--216",
  month = "April--June",
  year = "1985"
}

@article{ gottlob:nonmon,
  author = "Georg Gottlob",
  title = "Complexity results for nonmonotonic logics",
  journal = "Journal of Logic and Computation",
  volume = "2",
  number = "3",
  pages = "397--425",
  month = "June",
  year = "1992"
}

@misc{masterman2024landscapeemergingaiagent,
      title={The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey}, 
      author={Tula Masterman and Sandi Besen and Mason Sawtell and Alex Chao},
      year={2024},
      eprint={2404.11584},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2404.11584}, 
}

@article{ gls:hypertrees,
  author = "Georg Gottlob and Nicola Leone and Francesco Scarcello",
  title = "Hypertree Decompositions and Tractable Queries",
  journal = "Journal of Computer and System Sciences",
  volume = "64",
  number = "3",
  pages = "579--627",
  month = "May",
  year = "2002"
}

@article{ levesque:functional-foundations,
  author = "Hector~J. Levesque",
  title = "Foundations of a functional approach to knowledge representation",
  journal = "Artificial Intelligence",
  volume = "23",
  number = "2",
  pages = "155--212",
  month = "July",
  year = "1984"
}

@inproceedings{ levesque:belief,
  author = "Hector~J. Levesque",
  title = "A logic of implicit and explicit belief",
  booktitle = "Proceedings of the Fourth National Conference on Artificial Intelligence",
  publisher = "American Association for Artificial Intelligence",
  pages = "198--202",
  address = "Austin, Texas",
  month = "August",
  year = "1984"
}

@article{ nebel:jair-2000,
  author = "Bernhard Nebel",
  title = "On the compilability and expressive power of propositional planning formalisms",
  journal = "Journal of Artificial Intelligence Research",
  volume = "12",
  pages = "271--315",
  year = "2000"
}

@misc{proceedings,
  author = {{IJCAI Proceedings}},
  title = {{IJCAI} Camera Ready Submission},
  howpublished = {\url{https://proceedings.ijcai.org/info}},
}

@misc{wei2024medaideomnimedicalaide,
  title={MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration}, 
  author={Jinjie Wei and Dingkang Yang and Yanshu Li and Qingyao Xu and Zhaoyu Chen and Mingcheng Li and Yue Jiang and Xiaolu Hou and Lihua Zhang},
  year={2024},
  eprint={2410.12532},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2410.12532}
}

@misc{kim2024demonstrationadaptivecollaborationlarge,
  title={A Demonstration of Adaptive Collaboration of Large Language Models for Medical Decision-Making},
  author={Yubin Kim and Chanwoo Park and Hyewon Jeong and Cristina Grau-Vilchez and others},
  year={2024},
  eprint={2411.00248},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2411.00248}
}

@misc{shi2024ehragentcodeempowerslarge,
      title={EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records}, 
      author={Wenqi Shi and Ran Xu and Yuchen Zhuang and Yue Yu and Jieyu Zhang and Hang Wu and Yuanda Zhu and Joyce Ho and Carl Yang and May D. Wang},
      year={2024},
      eprint={2401.07128},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.07128}, 
}

@misc{li2024exploringllmmultiagentsicd,
      title={Exploring LLM Multi-Agents for ICD Coding}, 
      author={Rumeng Li and Xun Wang and Hong Yu},
      year={2024},
      eprint={2406.15363},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.15363}, 
}

@misc{zhu2024mentibridgingmedicalcalculator,
      title={MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling}, 
      author={Yakun Zhu and Shaohang Wei and Xu Wang and Kui Xue and Xiaofan Zhang and Shaoting Zhang},
      year={2024},
      eprint={2410.13610},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.13610}, 
}

@INPROCEEDINGS{10822109,
  author={Hong, Shengxin and Xiao, Liang and Zhang, Xin and Chen, Jianxia},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={ArgMed-Agents: Explainable Clinical Decision Reasoning with LLM Disscusion via Argumentation Schemes}, 
  year={2024},
  volume={},
  number={},
  pages={5486-5493},
  keywords={Decision support systems;Accuracy;Cognitive processes;Large language models;Directed graphs;Medical services;Probabilistic logic;Cognition;Natural language processing;Planning;Clinical Decision Support;Large Language Model;Multi-Agent System;Explainable AI},
  doi={10.1109/BIBM62325.2024.10822109}}

@article{yip2023artificial,
  author = {Michael Yip and Septimiu Salcudean and Ken Goldberg and Kaspar Althoefer and Arianna Menciassi and Justin D. Opfermann and Axel Krieger and Krithika Swaminathan and Conor J. Walsh and He (Helen) Huang and I-Chieh Lee},
  title = {Artificial intelligence meets medical robotics},
  journal = {Science},
  volume = {381},
  number = {6654},
  pages = {141--146},
  year = {2023},
  doi = {10.1126/science.adj3312},
  url = {https://www.science.org/doi/abs/10.1126/science.adj3312},
  eprint = {https://www.science.org/doi/pdf/10.1126/science.adj3312},
  abstract = {Artificial intelligence (AI) applications in medical robots are bringing a new era to medicine. Advanced medical robots can perform diagnostic and surgical procedures, aid rehabilitation, and provide symbiotic prosthetics to replace limbs. The technology used in these devices, including computer vision, medical image analysis, haptics, navigation, precise manipulation, and machine learning (ML), could allow autonomous robots to carry out diagnostic imaging, remote surgery, surgical subtasks, or even entire surgical procedures. Moreover, AI in rehabilitation devices and advanced prosthetics can provide individualized support, as well as improved functionality and mobility. The combination of extraordinary advances in robotics, medicine, materials science, and computing could bring safer, more efficient, and more widely available patient care in the future. --Gemma K. Alderton}
}

@article{chadebecq2023artificial,
  title   = {Artificial intelligence and automation in endoscopy and surgery},
  author  = {Chadebecq, F and Lovat, L.B. and Stoyanov, D.},
  journal = {Nature Reviews Gastroenterology \& Hepatology},
  volume  = {20},
  pages   = {171--182},
  year    = {2023},
  doi     = {10.1038/s41575-022-00701-y},
  url     = {https://doi.org/10.1038/s41575-022-00701-y},
  note    = {Accepted: 03 October 2022, Published: 09 November 2022, Issue Date: March 2023}
}


@article{laymouna2024roles,
  title   = {Roles, Users, Benefits, and Limitations of Chatbots in Health Care: Rapid Review},
  author  = {Laymouna, M and Ma, Y and Lessard, D and Schuster, T and Engler, K and Lebouch{\'e}, B},
  journal = {Journal of Medical Internet Research},
  volume  = {26},
  year    = {2024},
  pages   = {e56930},
  doi     = {10.2196/56930},
  url     = {https://www.jmir.org/2024/1/e56930}
}


@misc{swarmsofLLM2024,
  author = {Swarms},
  title = {Unlocking Efficiency and Cost Savings in Healthcare: How Swarms of LLM Agents Can Revolutionize Medical Operations and Save Millions},
  year = {2025},  
  url = {https://docs.swarms.world/en/latest/guides/healthcare_blog/?utm_source=chatgpt.com},
  note = {Accessed: 2025-02-04} 
}

@article{Pashangpour_2024,
  title = {The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare},
  author = {Pashangpour, Souren and Nejat, Goldie},
  journal = {Robotics},
  volume = {13},
  number = {8},
  pages = {112},
  year = {2024},
  month = jul,
  ISSN = {2218-6581},
  DOI = {10.3390/robotics13080112},
  url = {http://dx.doi.org/10.3390/robotics13080112},
  publisher = {MDPI AG}
}


@misc{zuo2025kg4diagnosishierarchicalmultiagentllm,
      title={KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis}, 
      author={Kaiwen Zuo and Yirui Jiang and Fan Mo and Pietro Lio},
      year={2025},
      eprint={2412.16833},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.16833}, 
}

@misc{tang2024medagentslargelanguagemodels,
  title={MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning},
  author={Xiangru Tang and Anni Zou and Zhuosheng Zhang and others},
  year={2024},
  eprint={2311.10537},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2311.10537}
}

@INPROCEEDINGS{10527275,
  author={Gebreab, Senay A. and Salah, Khaled and Jayaraman, Raja and Habib ur Rehman, Muhammad and Ellaham, Samer},
  booktitle={2024 12th International Symposium on Digital Forensics and Security (ISDFS)}, 
  title={LLM-Based Framework for Administrative Task Automation in Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  keywords={Processor scheduling;Soft sensors;Documentation;Safety;Security;Medical diagnosis;Task analysis;large language models;autonomous agents;health-care;electronic medical record;task automation;retrieval aug-mented generation},
  doi={10.1109/ISDFS60797.2024.10527275}}

@misc{yang2025llmmedqaenhancingmedicalquestion,
      title={LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models}, 
      author={Hang Yang and Hao Chen and Hui Guo and Yineng Chen and Ching-Sheng Lin and Shu Hu and Jinrong Hu and Xi Wu and Xin Wang},
      year={2025},
      eprint={2501.05464},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.05464}, 
}

@misc{yue2024clinicalagentclinicaltrialmultiagent,
  title={ClinicalAgent: Clinical Trial Multi-Agent System with Large Language Model-based Reasoning},
  author={Ling Yue and Sixue Xing and Jintai Chen and Tianfan Fu},
  year={2024},
  eprint={2404.14777},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2404.14777}
}

@misc{mukherjee2024polarissafetyfocusedllmconstellation,
  title={Polaris: A Safety-focused LLM Constellation Architecture for Healthcare},
  author={Subhabrata Mukherjee and Paul Gamble and Markel Sanz Ausin and others},
  year={2024},
  eprint={2403.13313},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2403.13313}
}

@misc{wei2024medcomedicaleducationcopilots,
  title={MEDCO: Medical Education Copilots Based on A Multi-Agent Framework},
  author={Hao Wei and Jianing Qiu and Haibao Yu and Wu Yuan},
  year={2024},
  eprint={2408.12496},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2408.12496}
}

@misc{yu2024aipatientsimulatingpatientsehrs,
  title={AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow},
  author={Huizi Yu and Jiayan Zhou and Lingyao Li and others},
  year={2024},
  eprint={2409.18924},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2409.18924}
}

@misc{li2024mmedagentlearningusemedical,
      title={MMedAgent: Learning to Use Medical Tools with Multi-modal Agent}, 
      author={Binxu Li and Tiankai Yan and Yuanting Pan and Jie Luo and Ruiyang Ji and Jiayuan Ding and Zhe Xu and Shilong Liu and Haoyu Dong and Zihao Lin and Yixin Wang},
      year={2024},
      eprint={2407.02483},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.02483}, 
}


@misc{jin2024agentmdempoweringlanguageagents,
      title={AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning}, 
      author={Qiao Jin and Zhizheng Wang and Yifan Yang and Qingqing Zhu and Donald Wright and Thomas Huang and W John Wilbur and Zhe He and Andrew Taylor and Qingyu Chen and Zhiyong Lu},
      year={2024},
      eprint={2402.13225},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13225}, 
}

@misc{wang2024colacareenhancingelectronichealth,
  title={ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration},
  author={Zixiang Wang and Yinghao Zhu and Huiya Zhao and others},
  year={2024},
  eprint={2410.02551},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/2410.02551}
}

@misc{lee2024improvingclinicaldocumentationai,
  title={Improving Clinical Documentation with AI: A Comparative Study of Sporo AI Scribe and GPT-4o mini},
  author={Chanseo Lee and Sonu Kumar and Kimon A. Vogt and Sam Meraj},
  year={2024},
  eprint={2410.15528},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2410.15528}
}

@article{achiam2023gpt,
    author = {Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
    journal = {ArXiv preprint},
    title = {Gpt-4 technical report},
    url = {https://arxiv.org/abs/2303.08774},
    volume = {abs/2303.08774},
    year = {2023}
}

@article{team2023gemini,
    author = {Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
    journal = {ArXiv preprint},
    title = {Gemini: a family of highly capable multimodal models},
    url = {https://arxiv.org/abs/2312.11805},
    volume = {abs/2312.11805},
    year = {2023}
}

@inproceedings{10.1145/3490099.3511105,
author = {Yuan, Ann and Coenen, Andy and Reif, Emily and Ippolito, Daphne},
title = {Wordcraft: Story Writing With Large Language Models},
year = {2022},
isbn = {9781450391443},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490099.3511105},
doi = {10.1145/3490099.3511105},
booktitle = {Proceedings of the 27th International Conference on Intelligent User Interfaces},
pages = {841–852},
numpages = {12},
keywords = {NLP},
location = {Helsinki, Finland},
series = {IUI '22}
}

@inproceedings{
chai2025empowering,
title={Empowering {LLM} Agents with Zero-Shot Optimal Decision-Making through Q-learning},
author={Jiajun Chai and Sicheng Li and Yuqian Fu and Dongbin Zhao and Yuanheng Zhu},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=JsVIGVntnQ}
}

@misc{sun2024applications,
  title={Applications, Challenges, and Prospects of Large Language Models in the Field of Clinical Medicine},
  author={SUN, Lei and WANG, An'an and SONG, Yimin and DONG, Jing and LIU, Xiaoli and LIANG, Hong and LI, Lixuan and SONG, Xinyu and FAN, Yong and JIA, Zhilong and others},
  journal={ACADEMIC JOURNAL OF CHINESE PLA MEDICAL SCHOOL},
  year={2024},
  publisher={Editorial Department of Journal of PLA Medical College}
}

@article{yan2025application,
  title={The Application of Large Language Models in Primary Healthcare Services and the Challenges},
  author={YAN, Wenxin and HU, Jian and ZENG, Huatang and LIU, Min and LIANG, Wannian},
  journal={Chinese General Practice},
  volume={28},
  number={01},
  pages={1},
  year={2025}
}

@misc{xi2023risepotentiallargelanguage,
      title={The Rise and Potential of Large Language Model Based Agents: A Survey}, 
      author={Zhiheng Xi and Wenxiang Chen and Xin Guo and Wei He and Yiwen Ding and Boyang Hong and Ming Zhang and Junzhe Wang and Senjie Jin and Enyu Zhou and Rui Zheng and Xiaoran Fan and Xiao Wang and Limao Xiong and Yuhao Zhou and Weiran Wang and Changhao Jiang and Yicheng Zou and Xiangyang Liu and Zhangyue Yin and Shihan Dou and Rongxiang Weng and Wensen Cheng and Qi Zhang and Wenjuan Qin and Yongyan Zheng and Xipeng Qiu and Xuanjing Huang and Tao Gui},
      year={2023},
      eprint={2309.07864},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2309.07864}, 
}

@book{russell2016artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Pearson}
}

@inproceedings{yuan-etal-2024-r,
    title = "{R}-Judge: Benchmarking Safety Risk Awareness for {LLM} Agents",
    author = "Yuan, Tongxin  and
      He, Zhiwei  and
      Dong, Lingzhong  and
      Wang, Yiming  and
      Zhao, Ruijie  and
      Xia, Tian  and
      Xu, Lizhen  and
      Zhou, Binglin  and
      Li, Fangqi  and
      Zhang, Zhuosheng  and
      Wang, Rui  and
      Liu, Gongshen",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.79/",
    doi = "10.18653/v1/2024.findings-emnlp.79",
    pages = "1467--1490",
    abstract = "Large language models (LLMs) have exhibited great potential in autonomously completing tasks across real-world applications. Despite this, these LLM agents introduce unexpected safety risks when operating in interactive environments. Instead of centering on the harmlessness of LLM-generated content in most prior studies, this work addresses the imperative need for benchmarking the behavioral safety of LLM agents within diverse environments. We introduce R-Judge, a benchmark crafted to evaluate the proficiency of LLMs in judging and identifying safety risks given agent interaction records. R-Judge comprises 569 records of multi-turn agent interaction, encompassing 27 key risk scenarios among 5 application categories and 10 risk types. It is of high-quality curation with annotated safety labels and risk descriptions. Evaluation of 11 LLMs on R-Judge shows considerable room for enhancing the risk awareness of LLMs: The best-performing model, GPT-4o, achieves 74.42{\%} while no other models significantly exceed the random. Moreover, we reveal that risk awareness in open agent scenarios is a multi-dimensional capability involving knowledge and reasoning, thus challenging for LLMs. With further experiments, we find that fine-tuning on safety judgment significantly improve model performance while straightforward prompting mechanisms fail. R-Judge is publicly available at Annoymous."
}

@misc{guo2024largelanguagemodelbased,
      title={Large Language Model based Multi-Agents: A Survey of Progress and Challenges}, 
      author={Taicheng Guo and Xiuying Chen and Yaqi Wang and Ruidi Chang and Shichao Pei and Nitesh V. Chawla and Olaf Wiest and Xiangliang Zhang},
      year={2024},
      eprint={2402.01680},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.01680}, 
}

@article{jiang2023mistral,
    author = {Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
    journal = {ArXiv preprint},
    title = {Mistral 7B},
    url = {https://arxiv.org/abs/2310.06825},
    volume = {abs/2310.06825},
    year = {2023}
}

@article{yang2024qwen2,
    author = {Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
    journal = {ArXiv preprint},
    title = {Qwen2 technical report},
    url = {https://arxiv.org/abs/2407.10671},
    volume = {abs/2407.10671},
    year = {2024}
}

@misc{wang2024directdiagnosisllmbasedmultispecialist,
      title={Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis}, 
      author={Haochun Wang and Sendong Zhao and Zewen Qiang and Nuwa Xi and Bing Qin and Ting Liu},
      year={2024},
      eprint={2401.16107},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.16107}, 
}

@article{dubey2024llama3,
    author = {Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
    journal = {ArXiv preprint},
    title = {The Llama 3 Herd of Models},
    url = {https://arxiv.org/abs/2407.21783},
    volume = {abs/2407.21783},
    year = {2024}
}

@misc{geminiteam2024gemini15unlockingmultimodal,
      title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}, 
      author={Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and others},
      year={2024},
      eprint={2403.05530},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.05530}, 
}

@misc{openai2024openaio1card,
      title={OpenAI o1 System Card}, 
      author={OpenAI and : and Aaron Jaech and Adam Kalai and Adam Lerer and others},
      year={2024},
      eprint={2412.16720},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.16720}, 
}

@article{li2024personal,
    author = {Li, Yuanchun and Wen, Hao and Wang, Weijun and Li, Xiangyu and Yuan, Yizhen and Liu, Guohong and Liu, Jiacheng and Xu, Wenxing and Wang, Xiang and Sun, Yi and others},
    journal = {ArXiv preprint},
    title = {Personal llm agents: Insights and survey about the capability, efficiency and security},
    url = {https://arxiv.org/abs/2401.05459},
    volume = {abs/2401.05459},
    year = {2024}
}

@article{liu2024aligning,
    author = {Liu, Yang and Chen, Weixing and Bai, Yongjie and Luo, Jingzhou and Song, Xinshuai and Jiang, Kaixuan and Li, Zhida and Zhao, Ganlong and Lin, Junyi and Li, Guanbin and others},
    journal = {ArXiv preprint},
    title = {Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI},
    url = {https://arxiv.org/abs/2407.06886},
    volume = {abs/2407.06886},
    year = {2024}
}

@article{chen2024mindsearch,
    author = {Chen, Zehui and Liu, Kuikun and Wang, Qiuchen and Liu, Jiangning and Zhang, Wenwei and Chen, Kai and Zhao, Feng},
    journal = {ArXiv preprint},
    title = {MindSearch: Mimicking Human Minds Elicits Deep AI Searcher},
    url = {https://arxiv.org/abs/2407.20183},
    volume = {abs/2407.20183},
    year = {2024}
}

@article{wang2024opendevin,
    author = {Wang, Xingyao and Li, Boxuan and Song, Yufan and Xu, Frank F and Tang, Xiangru and Zhuge, Mingchen and Pan, Jiayi and Song, Yueqi and Li, Bowen and Singh, Jaskirat and others},
    journal = {ArXiv preprint},
    title = {OpenDevin: An Open Platform for AI Software Developers as Generalist Agents},
    url = {https://arxiv.org/abs/2407.16741},
    volume = {abs/2407.16741},
    year = {2024}
}


@misc{liu2024medchainbridginggapllm,
  title={Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking}, 
  author={Jie Liu and Wenxuan Wang and Zizhan Ma and Guolin Huang and Yihang Su and Kao-Jung Chang and Wenting Chen and Haoliang Li and Linlin Shen and Michael Lyu},
  year={2024},
  eprint={2412.01605},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2412.01605}
}

@article{Mehandru2024EvaluatingLL,
  title={Evaluating large language models as agents in the clinic},
  author={Nikita Mehandru and Brenda Y Miao and Eduardo Rodriguez Almaraz and Madhumita Sushil and Atul Janardhan Butte and Ahmed Alaa},
  journal={NPJ Digital Medicine},
  year={2024},
  volume={7},
  url={https://api.semanticscholar.org/CorpusID:268887942}
}

@misc{huang2024benchmarkinglargelanguagemodels,
      title={Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset}, 
      author={Hengguan Huang and Songtao Wang and Hongfu Liu and Hao Wang and Ye Wang},
      year={2024},
      eprint={2402.05547},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.05547}, 
}

@misc{schmidgall2024agentclinic,
  title={AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments}, 
  author={Samuel Schmidgall and Rojin Ziaei and Carl Harris and Eduardo Reis and Jeffrey Jopling and Michael Moor},
  year={2024},
  eprint={2405.07960},
  archivePrefix={arXiv},
  primaryClass={cs.HC}
}

@misc{yan2024clinicallabaligningagentsmultidepartmental,
  title={ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World}, 
  author={Weixiang Yan and Haitian Liu and Tengxiao Wu and Qian Chen and Wen Wang and Haoyuan Chai and Jiayi Wang and Weishan Zhao and Yixin Zhang and Renjun Zhang and Li Zhu and Xuandong Zhao},
  year={2024},
  eprint={2406.13890},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2406.13890}
}

@misc{baniharouni2024magdamultiagentguidelinedrivendiagnostic,
      title={MAGDA: Multi-agent guideline-driven diagnostic assistance}, 
      author={David Bani-Harouni and Nassir Navab and Matthias Keicher},
      year={2024},
      eprint={2409.06351},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2409.06351}, 
}

@inproceedings{10.1145/3637528.3671575,
  author = {Liu, Lei and Yang, Xiaoyan and Li, Fangzhou and Chi, Chenfei and Shen, Yue and Lyu, Shiwei and Zhang, Ming and Ma, Xiaowei and Lv, Xiangguo and Ma, Liya and Zhang, Zhiqiang and Xue, Wei and Huang, Yiran and Gu, Jinjie},
  title = {Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric, Data, and Algorithm},
  year = {2024},
  isbn = {9798400704901},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3637528.3671575},
  doi = {10.1145/3637528.3671575},
  booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages = {5466--5475},
  keywords = {evaluation benchmark, large language model, medical ai},
  location = {Barcelona, Spain},
  series = {KDD '24}
}

@misc{dutta2024adaptivereasoningactingmedical,
  title={Adaptive Reasoning and Acting in Medical Language Agents}, 
  author={Abhishek Dutta and Yen-Che Hsiao},
  year={2024},
  eprint={2410.10020},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2410.10020}
}

@article{info:doi/10.2196/59439,
  author={Yuhe Ke and Rui Yang and Sui An Lie and Taylor Xin Yi Lim and Yilin Ning and Irene Li and Hairil Rizal Abdullah and Daniel Shu Wei Ting and Nan Liu},
  title={Mitigating Cognitive Biases in Clinical Decision-Making Through Multi-Agent Conversations Using Large Language Models: Simulation Study},
  journal={J Med Internet Res},
  year={2024},
  volume={26},
  pages={e59439},
  doi={10.2196/59439},
  url={https://www.jmir.org/2024/1/e59439}
}

@misc{van2024rxstrategistprescriptionverification,
  title={Rx Strategist: Prescription Verification using LLM Agents System}, 
  author={Phuc Phan Van and Dat Nguyen Minh and An Dinh Ngoc and Huy Phan Thanh},
  year={2024},
  eprint={2409.03440},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2409.03440}
}

@misc{kim2024mdagentsadaptivecollaborationllms,
      title={MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making}, 
      author={Yubin Kim and Chanwoo Park and Hyewon Jeong and Yik Siu Chan and Xuhai Xu and Daniel McDuff and Hyeonhoon Lee and Marzyeh Ghassemi and Cynthia Breazeal and Hae Won Park},
      year={2024},
      eprint={2404.15155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.15155}, 
}

@article{Huang_2024,
   title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
   ISSN={1558-2868},
   url={http://dx.doi.org/10.1145/3703155},
   DOI={10.1145/3703155},
   journal={ACM Transactions on Information Systems},
   publisher={Association for Computing Machinery (ACM)},
   author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
   year={2024},
   month=nov }

@misc{cai2023medbenchlargescalechinesebenchmark,
      title={MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models}, 
      author={Yan Cai and Linlin Wang and Ye Wang and Gerard de Melo and Ya Zhang and Yanfeng Wang and Liang He},
      year={2023},
      eprint={2312.12806},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.12806}, 
}

@misc{sudarshan2024agenticllmworkflowsgenerating,
  title={Agentic LLM Workflows for Generating Patient-Friendly Medical Reports}, 
  author={Malavikha Sudarshan and Sophie Shih and Estella Yee and Alina Yang and John Zou and Cathy Chen and Quan Zhou and Leon Chen and Chinmay Singhal and George Shih},
  year={2024},
  eprint={2408.01112},
  archivePrefix={arXiv},
  primaryClass={cs.MA},
  url={https://arxiv.org/abs/2408.01112}
}



@misc{wu2024surgboxagentdrivenoperatingroom,
  title={SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot}, 
  author={Jinlin Wu and Xusheng Liang and Xuexue Bai and Zhen Chen},
  year={2024},
  eprint={2412.05187},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2412.05187}
}

@misc{li2024agenthospitalsimulacrumhospital,
  title={Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents}, 
  author={Junkai Li and Siyu Wang and Meng Zhang and Weitao Li and Yunghwei Lai and Xinhui Kang and Weizhi Ma and Yang Liu},
  year={2024},
  eprint={2405.02957},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/2405.02957}
}

@misc{fan2024aihospitalbenchmarkinglarge,
  title={AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical Interaction Simulator}, 
  author={Zhihao Fan and Jialong Tang and Wei Chen and Siyuan Wang and Zhongyu Wei and Jun Xi and Fei Huang and Jingren Zhou},
  year={2024},
  eprint={2402.09742},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2402.09742}
}

@misc{liu2024automatic,
      title={Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric, Data, and Algorithm}, 
      author={Lei Liu and Xiaoyan Yang and Fangzhou Li and Chenfei Chi and Yue Shen and Shiwei Lyu and Ming Zhang and Xiaowei Ma and Xiangguo Lyu and Liya Ma and Zhiqiang Zhang and Wei Xue and Yiran Huang and Jinjie Gu},
      year={2024},
      eprint={2403.16446},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{dou2024exploringllmbaseddataannotation,
      title={Exploring LLM-based Data Annotation Strategies for Medical Dialogue Preference Alignment}, 
      author={Chengfeng Dou and Ying Zhang and Zhi Jin and Wenpin Jiao and Haiyan Zhao and Yongqiang Zhao and Zhengwei Tao},
      year={2024},
      eprint={2410.04112},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.04112},
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}

@misc{zhou2023leasttomostpromptingenablescomplex,
      title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models}, 
      author={Denny Zhou and Nathanael Schärli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Claire Cui and Olivier Bousquet and Quoc Le and Ed Chi},
      year={2023},
      eprint={2205.10625},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2205.10625}, 
}

@misc{yao2023reactsynergizingreasoningacting,
      title={ReAct: Synergizing Reasoning and Acting in Language Models}, 
      author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
      year={2023},
      eprint={2210.03629},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.03629}, 
}

@inproceedings{kim2024mdagents,
  title={Mdagents: An adaptive collaboration of llms for medical decision-making},
  author={Kim, Yubin and Park, Chanwoo and Jeong, Hyewon and Chan, Yik Siu and Xu, Xuhai and McDuff, Daniel and Lee, Hyeonhoon and Ghassemi, Marzyeh and Breazeal, Cynthia and Park, Hae Won},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@article{schmidgall2024addressing,
  title={Addressing cognitive bias in medical language models},
  author={Schmidgall, Samuel and Harris, Carl and Essien, Ime and Olshvang, Daniel and Rahman, Tawsifur and Kim, Ji Woong and Ziaei, Rojin and Eshraghian, Jason and Abadir, Peter and Chellappa, Rama},
  journal={arXiv preprint arXiv:2402.08113},
  year={2024}
} 
@article{kandpal2023user,
  title={User inference attacks on large language models},
  author={Kandpal, Nikhil and Pillutla, Krishna and Oprea, Alina and Kairouz, Peter and Choquette-Choo, Christopher A and Xu, Zheng},
  journal={arXiv preprint arXiv:2310.09266},
  year={2023}
}
@inproceedings{carlini2021extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}
@article{gdpr2016general,
  title={General data protection regulation},
  author={GDPR, GDPR},
  journal={Regulation (EU)},
  volume={679},
  year={2016}
}
@article{act1996health,
  title={Health insurance portability and accountability act of 1996},
  author={Act, Accountability},
  journal={Public law},
  volume={104},
  pages={191},
  year={1996}
}
@article{zuo2024medhallbench,
  title={MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models},
  author={Zuo, Kaiwen and Jiang, Yirui},
  journal={arXiv preprint arXiv:2412.18947},
  year={2024}
}
@article{li2023halueval,
  title={Halueval: A large-scale hallucination evaluation benchmark for large language models},
  author={Li, Junyi and Cheng, Xiaoxue and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.11747},
  year={2023}
}

@misc{jin2020diseasedoespatienthave,
      title={What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams}, 
      author={Di Jin and Eileen Pan and Nassim Oufattole and Wei-Hung Weng and Hanyi Fang and Peter Szolovits},
      year={2020},
      eprint={2009.13081},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2009.13081}, 
}


@InProceedings{pmlr-v174-pal22a,
  title = 	 {MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering},
  author =       {Pal, Ankit and Umapathi, Logesh Kumar and Sankarasubbu, Malaikannan},
  booktitle = 	 {Proceedings of the Conference on Health, Inference, and Learning},
  pages = 	 {248--260},
  year = 	 {2022},
  editor = 	 {Flores, Gerardo and Chen, George H and Pollard, Tom and Ho, Joyce C and Naumann, Tristan},
  volume = 	 {174},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07--08 Apr},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v174/pal22a/pal22a.pdf},
  url = 	 {https://proceedings.mlr.press/v174/pal22a.html},
  abstract = 	 {This paper introduces MedMCQA, a new large-scale, Multiple-Choice Question Answering (MCQA) dataset designed to address real-world medical entrance exam questions. More than 194k high-quality AIIMS &amp; NEET PG entrance exam MCQs covering 2.4k healthcare topics and 21 medical subjects are collected with an average token length of 12.77 and high topical diversity. Each sample contains a question, correct answer(s), and other options which requires a deeper language understanding as it tests the 10+ reasoning abilities of a model across a wide range of medical subjects &amp; topics. A detailed explanation of the solution, along with the above information, is provided in this study.}
}

@inproceedings{jin2019pubmedqa,
  title={PubMedQA: A Dataset for Biomedical Research Question Answering},
  author={Jin, Qiao and Dhingra, Bhuwan and Liu, Zhengping and Cohen, William and Lu, Xinghua},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={2567--2577},
  year={2019}
}

@article{hendryckstest2021,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{hendrycks2021ethics,
  title={Aligning AI With Shared Human Values},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and Jerry Li and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    editor = "Isabelle, Pierre  and
      Charniak, Eugene  and
      Lin, Dekang",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P02-1040/",
    doi = "10.3115/1073083.1073135",
    pages = "311--318"
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013/",
    pages = "74--81"
}

@misc{zhang2020bertscoreevaluatingtextgeneration,
      title={BERTScore: Evaluating Text Generation with BERT}, 
      author={Tianyi Zhang and Varsha Kishore and Felix Wu and Kilian Q. Weinberger and Yoav Artzi},
      year={2020},
      eprint={1904.09675},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.09675}, 
}

@article{nursingrobot,
  author={Zhao, Zhendong and Yue, Xiaotian and Xie, Jiexin and Fang, Chuanhong and Shao, Zhenzhou and Guo, Shijie},
  journal={IEEE Robotics and Automation Letters}, 
  title={A Dual-Agent Collaboration Framework Based on LLMs for Nursing Robots to Perform Bimanual Coordination Tasks}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  keywords={Robots;Robot kinematics;Medical services;Collaboration;Manipulators;Planning;Torso;Arms;Multi-agent systems;Decision making;Nursing robot;bimanual coordination tasks;LLMs-based dual-agent},
  doi={10.1109/LRA.2025.3533476}}

@article{Qiu2024,
  author = {Qiu, Jianing and Lam, Kyle and Li, Guohao and Acharya, Amish and Wong, Tien Yin and Darzi, Ara and Yuan, Wu and Topol, Eric J.},
  title = {LLM-based agentic systems in medicine and healthcare},
  journal = {Nature Machine Intelligence},
  year = {2024},
  volume = {6},
  number = {12},
  pages = {1418--1420},
  month = {December},
  doi = {10.1038/s42256-024-00944-1},
  abstract = {Large language model-based agentic systems can process input information, plan and decide, recall and reflect, interact and collaborate, leverage various tools and act. This opens up a wealth of opportunities within medicine and healthcare, ranging from clinical workflow automation to multi-agent-aided diagnosis.},
  issn = {2522-5839}
}


@article{Brgge2024LargeLM,
  title={Large language models improve clinical decision making of medical students through patient simulation and structured feedback: a randomized controlled trial},
  author={Emilia Br{\"u}gge and Sarah Ricchizzi and Malin Arenbeck and Marius Niklas Keller and Lina Schur and Walter Stummer and Markus Holling and Max Hao Lu and Dogus Darici},
  journal={BMC Medical Education},
  year={2024},
  volume={24},
  url={https://api.semanticscholar.org/CorpusID:274369479}
}

@misc{zheng2024largelanguagemodelsmedicine,
      title={Large Language Models for Medicine: A Survey}, 
      author={Yanxin Zheng and Wensheng Gan and Zefeng Chen and Zhenlian Qi and Qian Liang and Philip S. Yu},
      year={2024},
      eprint={2405.13055},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.13055}, 
}

@misc{chen2024evaluatinglargelanguagemodels,
      title={Evaluating large language models in medical applications: a survey}, 
      author={Xiaolan Chen and Jiayang Xiang and Shanfu Lu and Yexin Liu and Mingguang He and Danli Shi},
      year={2024},
      eprint={2405.07468},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.07468}, 
}

@misc{yuan2023largelanguagemodelsilluminate,
      title={Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review}, 
      author={Mingze Yuan and Peng Bao and Jiajia Yuan and Yunhao Shen and Zifan Chen and Yi Xie and Jie Zhao and Yang Chen and Li Zhang and Lin Shen and Bin Dong},
      year={2023},
      eprint={2311.01918},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.01918}, 
}

@misc{mehandru2023largelanguagemodelsagents,
      title={Large Language Models as Agents in the Clinic}, 
      author={Nikita Mehandru and Brenda Y. Miao and Eduardo Rodriguez Almaraz and Madhumita Sushil and Atul J. Butte and Ahmed Alaa},
      year={2023},
      eprint={2309.10895},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2309.10895}, 
}

@misc{singhal2023expertlevelmedicalquestionanswering,
      title={Towards Expert-Level Medical Question Answering with Large Language Models}, 
      author={Karan Singhal and Tao Tu and Juraj Gottweis and Rory Sayres and Ellery Wulczyn and Le Hou and Kevin Clark and Stephen Pfohl and Heather Cole-Lewis and Darlene Neal and Mike Schaekermann and Amy Wang and Mohamed Amin and Sami Lachgar and Philip Mansfield and Sushant Prakash and Bradley Green and Ewa Dominowska and Blaise Aguera y Arcas and Nenad Tomasev and Yun Liu and Renee Wong and Christopher Semturs and S. Sara Mahdavi and Joelle Barral and Dale Webster and Greg S. Corrado and Yossi Matias and Shekoofeh Azizi and Alan Karthikesalingam and Vivek Natarajan},
      year={2023},
      eprint={2305.09617},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.09617}, 
}

@article{Wang_2024,
   title={A survey on large language model based autonomous agents},
   volume={18},
   ISSN={2095-2236},
   url={http://dx.doi.org/10.1007/s11704-024-40231-1},
   DOI={10.1007/s11704-024-40231-1},
   number={6},
   journal={Frontiers of Computer Science},
   publisher={Springer Science and Business Media LLC},
   author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and Zhao, Wayne Xin and Wei, Zhewei and Wen, Jirong},
   year={2024},
   month=mar }


@misc{cheng2024exploringlargelanguagemodel,
      title={Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects}, 
      author={Yuheng Cheng and Ceyao Zhang and Zhengwen Zhang and Xiangrui Meng and Sirui Hong and Wenhao Li and Zihao Wang and Zekai Wang and Feng Yin and Junhua Zhao and Xiuqiang He},
      year={2024},
      eprint={2401.03428},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2401.03428}, 
}

@misc{du2024llmssimulatestandardizedpatients,
      title={LLMs Can Simulate Standardized Patients via Agent Coevolution}, 
      author={Zhuoyun Du and Lujie Zheng and Renjun Hu and Yuyang Xu and Xiawei Li and Ying Sun and Wei Chen and Jian Wu and Haolei Cai and Haohao Ying},
      year={2024},
      eprint={2412.11716},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.11716}, 
}

@misc{yao2023treethoughtsdeliberateproblem,
      title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models}, 
      author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
      year={2023},
      eprint={2305.10601},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.10601}, 
}

@misc{huang2025o1replicationjourney,
      title={O1 Replication Journey -- Part 3: Inference-time Scaling for Medical Reasoning}, 
      author={Zhongzhen Huang and Gui Geng and Shengyi Hua and Zhen Huang and Haoyang Zou and Shaoting Zhang and Pengfei Liu and Xiaofan Zhang},
      year={2025},
      eprint={2501.06458},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.06458}, 
}

@article{faray2025does,
  title={How does DeepSeek-R1 perform on USMLE?},
  author={Faray de Paiva, Lisle and Luijten, Gijs and Puladi, Behrus and Egger, Jan},
  journal={medRxiv},
  pages={2025--02},
  year={2025},
  publisher={Cold Spring Harbor Laboratory Press}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@misc{xu2024nextgenerationmedicalagento1,
      title={Towards Next-Generation Medical Agent: How o1 is Reshaping Decision-Making in Medical Scenarios}, 
      author={Shaochen Xu and Yifan Zhou and Zhengliang Liu and Zihao Wu and Tianyang Zhong and Huaqin Zhao and Yiwei Li and Hanqi Jiang and Yi Pan and Junhao Chen and Jin Lu and Wei Zhang and Tuo Zhang and Lu Zhang and Dajiang Zhu and Xiang Li and Wei Liu and Quanzheng Li and Andrea Sikora and Xiaoming Zhai and Zhen Xiang and Tianming Liu},
      year={2024},
      eprint={2411.14461},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.14461}, 
}

@misc{jiang2024longtermmemoryfoundation,
      title={Long Term Memory: The Foundation of AI Self-Evolution}, 
      author={Xun Jiang and Feng Li and Han Zhao and Jiaying Wang and Jun Shao and Shihao Xu and Shu Zhang and Weiling Chen and Xavier Tang and Yize Chen and Mengyue Wu and Weizhi Ma and Mengdi Wang and Tianqiao Chen},
      year={2024},
      eprint={2410.15665},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.15665}, 
}